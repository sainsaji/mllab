{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "qqp.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "lab1"
      ],
      "metadata": {
        "id": "lCfk05VvzqIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "lab1\n",
        "https://colab.research.google.com/drive/18TcSju1sqUUVubvLeYPoaHbdQhct733i?usp=sharing\n",
        "lab2\n",
        "https://colab.research.google.com/drive/1PKlqFWNFrrHuBWIE8SGqtrFPXrIxYWit?usp=sharing\n",
        "lab3\n",
        "https://colab.research.google.com/drive/1kKGn5vuekZHVAxMDYfc9oi3Y3VbGuEFM?usp=sharing\n",
        "lab4\n",
        "https://colab.research.google.com/drive/1eBdk_UaeAC7B_RMZcA2ZxUGm97KbzCR-?usp=sharing\n",
        "lab 5\n",
        "https://colab.research.google.com/drive/1YTTmCs7TJcRGAyBExH1g9R6Ehlf9kUWP?usp=sharing"
      ],
      "metadata": {
        "id": "hPEZmrJRzvwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Nearest Neighbour is one of the simplest Machine Learning algorithms based on Supervised Learning technique.\n",
        "K-NN algorithm assumes the similarity between the new case/data and available cases and put the new case into the category that is most similar to the available categories.\n",
        "K-NN algorithm stores all the available data and classifies a new data point based on the similarity. This means when new data appears then it can be easily classified into a well suite category by using K- NN algorithm.\n",
        "K-NN algorithm can be used for Regression as well as for Classification but mostly it is used for the Classification problems.\n",
        "K-NN is a non-parametric algorithm, which means it does not make any assumption on underlying data.\n",
        "It is also called a lazy learner algorithm because it does not learn from the training set immediately instead it stores the dataset and at the time of classification, it performs an action on the dataset.\n",
        "KNN algorithm at the training phase just stores the dataset and when it gets new data, then it classifies that data into a category that is much similar to the new data.\n",
        "Example: Suppose, we have an image of a creature that looks similar to cat and dog, but we want to know either it is a cat or dog. So for this identification, we can use the KNN algorithm, as it works on a similarity measure. Our KNN model will find the similar features of the new data set to the cats and dogs images and based on the most similar features it will put it in either cat or dog category."
      ],
      "metadata": {
        "id": "mbIChvSR0hqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-1: Select the number K of the neighbors\n",
        "Step-2: Calculate the Euclidean distance of K number of neighbors\n",
        "Step-3: Take the K nearest neighbors as per the calculated Euclidean distance.\n",
        "Step-4: Among these k neighbors, count the number of the data points in each category.\n",
        "Step-5: Assign the new data points to that category for which the number of the neighbor is maximum.\n",
        "Step-6: Our model is ready."
      ],
      "metadata": {
        "id": "8-SadMsy0zHi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This article was published as a part of the Data Science Blogathon.\n",
        "Introduction\n",
        "With the rising use of the Internet in today’s society, the quantity of data created is incomprehensibly huge. Even though the nature of individual data is straightforward, the sheer amount of data to be analyzed makes processing difficult for even computers.\n",
        "\n",
        "To manage such procedures, we need large data analysis tools. Data mining methods and techniques, in conjunction with machine learning, enable us to analyze large amounts of data in an intelligible manner. k-means is a technique for data clustering that may be used for unsupervised machine learning. It is capable of classifying unlabeled data into a predetermined number of clusters based on similarities (k).\n",
        "\n",
        "Introduction to K-Means Algorithm\n",
        "The K-means clustering algorithm computes centroids and repeats until the optimal centroid is found. It is presumptively known how many clusters there are. It is also known as the flat clustering algorithm. The number of clusters found from data by the method is denoted by the letter ‘K’ in K-means.\n",
        "\n",
        "In this method, data points are assigned to clusters in such a way that the sum of the squared distances between the data points and the centroid is as small as possible. It is essential to note that reduced diversity within clusters leads to more identical data points within the same cluster.\n",
        "\n",
        "Working of K-Means Algorithm\n",
        "The following stages will help us understand how the K-Means clustering technique works-\n",
        "\n",
        "Step 1: First, we need to provide the number of clusters, K, that need to be generated by this algorithm.\n",
        "Step 2: Next, choose K data points at random and assign each to a cluster. Briefly, categorize the data based on the number of data points.\n",
        "Step 3: The cluster centroids will now be computed.\n",
        "Step 4: Iterate the steps below until we find the ideal centroid, which is the assigning of data points to clusters that do not vary.\n",
        "4.1 The sum of squared distances between data points and centroids would be calculated first.\n",
        "4.2 At this point, we need to allocate each data point to the cluster that is closest to the others (centroid).\n",
        "4.3 Finally, compute the centroids for the clusters by averaging all of the cluster’s data points.\n",
        "K-means implements the Expectation-Maximization strategy to solve the problem. The Expectation-step is used to assign data points to the nearest cluster, and the Maximization-step is used to compute the centroid of each cluster.\n",
        "\n",
        "When using the K-means algorithm, we must keep the following points in mind:\n",
        "It is suggested to normalize the data while dealing with clustering algorithms such as K-Means since such algorithms employ distance-based measurement to identify the similarity between data points.\n",
        "Because of the iterative nature of K-Means and the random initialization of centroids, K-Means may become stuck in a local optimum and fail to converge to the global optimum. As a result, it is advised to employ distinct centroids’ initializations.\n",
        "Implementation of K Means Clustering Graphical Form\n",
        "STEP 1: Let us pick k clusters, i.e., K=2, to separate the dataset and assign it to its appropriate clusters. We will select two random places to function as the cluster’s centroid.\n",
        "\n",
        "STEP 2: Now, each data point will be assigned to a scatter plot depending on its distance from the nearest K-point or centroid. This will be accomplished by establishing a median between both centroids. Consider the following illustration:\n",
        "\n",
        "Loading Image\n",
        "Data Science Immersive Bootcamp\n",
        "Learn Data Science through industry relevant projects with FLAT ₹30,000 OFF\n",
        "STEP 3: The points on the line’s left side are close to the blue centroid, while the points on the line’s right side are close to the yellow centroid. The left Form cluster has a blue centroid, whereas the right Form cluster has a yellow centroid.\n",
        "\n",
        "STEP 4: Repeat the procedure, this time selecting a different centroid. To choose the new centroids, we will determine their new center of gravity, which is represented below:\n",
        "\n",
        "STEP 5: After that, we’ll re-assign each data point to its new centroid. We shall repeat the procedure outlined before (using a median line). The blue cluster will contain the yellow data point on the blue side of the median line.\n",
        "\n",
        "first step k means \n",
        "STEP 6: Now that reassignment has occurred, we will repeat the previous step of locating new centroids.\n",
        "\n",
        "scatter plot\n",
        "STEP 7: We will repeat the procedure outlined above for determining the center of gravity of centroids, as shown below.\n",
        "\n",
        "k means\n",
        "STEP 8: Similar to the previous stages, we will draw the median line and reassign the data points after locating the new centroids.\n",
        "\n",
        "k means\n",
        "STEP 9: We will finally group points depending on their distance from the median line, ensuring that two distinct groups are established and that no dissimilar points are included in a single group.\n",
        "\n",
        "k means plot\n",
        "The final Cluster is as follows:\n",
        "\n",
        "final cluster k means\n",
        " \n",
        "\n",
        "Implementation in Python\n",
        "To further understand K-Means clustering, let’s look at two real-world situations.\n",
        "\n",
        "Example 1\n",
        "\n",
        "This is a simple example of how k-means works. In this example, we will first construct a 2D dataset with four distinct blobs and then use the k-means algorithm to observe the results.\n",
        "\n",
        "To begin, we will import the essential packages.\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "The code below will build a 2D dataset with four blobs.\n",
        "\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "X, y_true = make_blobs(n_samples=400, centers=4, cluster_std=0.60, random_state=0)\n",
        "Following that, the code below will assist us in visualizing the dataset.\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], s=20);\n",
        "plt.show()\n",
        "clustering plot\n",
        "Next, create a K – means object while specifying the number of clusters, train the model, and estimate as follows-"
      ],
      "metadata": {
        "id": "3oGQjVr51z1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QIX19FKn11dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sainsaji/mllab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLhvMYY1ByWj",
        "outputId": "37da92b3-0d9d-47d4-9cc0-96a879cfea95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mllab' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IayrZCzl-qoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}